{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60c19755-ab52-4f99-87a0-e4e272d1545e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77ec9a14-494b-4550-972a-45f72c91755c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trtbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalachh</th>\n",
       "      <th>exng</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slp</th>\n",
       "      <th>caa</th>\n",
       "      <th>thall</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>140</td>\n",
       "      <td>241</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>123</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>110</td>\n",
       "      <td>264</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1.2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>303 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  sex  cp  trtbps  chol  fbs  restecg  thalachh  exng  oldpeak  slp  \\\n",
       "0     63    1   3     145   233    1        0       150     0      2.3    0   \n",
       "1     37    1   2     130   250    0        1       187     0      3.5    0   \n",
       "2     41    0   1     130   204    0        0       172     0      1.4    2   \n",
       "3     56    1   1     120   236    0        1       178     0      0.8    2   \n",
       "4     57    0   0     120   354    0        1       163     1      0.6    2   \n",
       "..   ...  ...  ..     ...   ...  ...      ...       ...   ...      ...  ...   \n",
       "298   57    0   0     140   241    0        1       123     1      0.2    1   \n",
       "299   45    1   3     110   264    0        1       132     0      1.2    1   \n",
       "300   68    1   0     144   193    1        1       141     0      3.4    1   \n",
       "301   57    1   0     130   131    0        1       115     1      1.2    1   \n",
       "302   57    0   1     130   236    0        0       174     0      0.0    1   \n",
       "\n",
       "     caa  thall  output  \n",
       "0      0      1       1  \n",
       "1      0      2       1  \n",
       "2      0      2       1  \n",
       "3      0      2       1  \n",
       "4      0      2       1  \n",
       "..   ...    ...     ...  \n",
       "298    0      3       0  \n",
       "299    0      3       0  \n",
       "300    2      3       0  \n",
       "301    1      3       0  \n",
       "302    1      2       0  \n",
       "\n",
       "[303 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('heart.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b1a9ba-edcb-41fc-9841-ab5c4ff21ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns='output')\n",
    "y = df['output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9b9261e2-f68c-4056-a590-a3ceea2feca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b032c049-868e-4848-bdd2-978c37aec441",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5a84d81-0dad-4d1a-a1b5-74860a7e534d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 14:49:15.799785: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-19 14:49:16.591604: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 79125 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:b7:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential([\n",
    "    layers.Dense(16, input_dim=13, activation='relu'),\n",
    "    layers.Dense(8, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c142450a-5558-460a-a64a-f680c23e7e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46115c51-c050-4d16-9a12-0e07ff9dd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 14:49:34.889815: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8/8 [==============================] - 1s 16ms/step - loss: 0.7060 - accuracy: 0.5496 - val_loss: 0.7102 - val_accuracy: 0.4590\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5826 - val_loss: 0.6865 - val_accuracy: 0.4918\n",
      "Epoch 3/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.6405 - val_loss: 0.6656 - val_accuracy: 0.5738\n",
      "Epoch 4/100\n",
      "1/8 [==>...........................] - ETA: 0s - loss: 0.6730 - accuracy: 0.5938"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-19 14:49:36.040262: I tensorflow/stream_executor/cuda/cuda_blas.cc:1760] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 4ms/step - loss: 0.6440 - accuracy: 0.6777 - val_loss: 0.6462 - val_accuracy: 0.6230\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6264 - accuracy: 0.7025 - val_loss: 0.6285 - val_accuracy: 0.6885\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.6100 - accuracy: 0.7231 - val_loss: 0.6113 - val_accuracy: 0.6885\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5951 - accuracy: 0.7438 - val_loss: 0.5952 - val_accuracy: 0.7049\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5804 - accuracy: 0.7603 - val_loss: 0.5803 - val_accuracy: 0.7541\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5659 - accuracy: 0.7645 - val_loss: 0.5648 - val_accuracy: 0.7705\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5518 - accuracy: 0.7727 - val_loss: 0.5493 - val_accuracy: 0.8033\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5376 - accuracy: 0.7769 - val_loss: 0.5337 - val_accuracy: 0.8033\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5223 - accuracy: 0.7975 - val_loss: 0.5193 - val_accuracy: 0.8197\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8017 - val_loss: 0.5058 - val_accuracy: 0.8197\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.4948 - accuracy: 0.8099 - val_loss: 0.4936 - val_accuracy: 0.8197\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.8182 - val_loss: 0.4832 - val_accuracy: 0.8197\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4692 - accuracy: 0.8223 - val_loss: 0.4734 - val_accuracy: 0.8197\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4576 - accuracy: 0.8264 - val_loss: 0.4635 - val_accuracy: 0.8361\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.8264 - val_loss: 0.4559 - val_accuracy: 0.8361\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4354 - accuracy: 0.8306 - val_loss: 0.4477 - val_accuracy: 0.8361\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4250 - accuracy: 0.8306 - val_loss: 0.4412 - val_accuracy: 0.8361\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4158 - accuracy: 0.8223 - val_loss: 0.4348 - val_accuracy: 0.8361\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.4061 - accuracy: 0.8306 - val_loss: 0.4292 - val_accuracy: 0.8361\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.8264 - val_loss: 0.4250 - val_accuracy: 0.8361\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3900 - accuracy: 0.8347 - val_loss: 0.4196 - val_accuracy: 0.8361\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3821 - accuracy: 0.8306 - val_loss: 0.4156 - val_accuracy: 0.8361\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3751 - accuracy: 0.8430 - val_loss: 0.4124 - val_accuracy: 0.8361\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3686 - accuracy: 0.8512 - val_loss: 0.4095 - val_accuracy: 0.8361\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3622 - accuracy: 0.8512 - val_loss: 0.4077 - val_accuracy: 0.8361\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8512 - val_loss: 0.4056 - val_accuracy: 0.8361\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3508 - accuracy: 0.8512 - val_loss: 0.4045 - val_accuracy: 0.8361\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3455 - accuracy: 0.8554 - val_loss: 0.4047 - val_accuracy: 0.8361\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3410 - accuracy: 0.8554 - val_loss: 0.4054 - val_accuracy: 0.8361\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8595 - val_loss: 0.4049 - val_accuracy: 0.8361\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8595 - val_loss: 0.4052 - val_accuracy: 0.8361\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8636 - val_loss: 0.4012 - val_accuracy: 0.8361\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8636 - val_loss: 0.4023 - val_accuracy: 0.8361\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3203 - accuracy: 0.8636 - val_loss: 0.4030 - val_accuracy: 0.8361\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8636 - val_loss: 0.4040 - val_accuracy: 0.8361\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8636 - val_loss: 0.4044 - val_accuracy: 0.8361\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8636 - val_loss: 0.4059 - val_accuracy: 0.8361\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8636 - val_loss: 0.4102 - val_accuracy: 0.8197\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.3039 - accuracy: 0.8636 - val_loss: 0.4100 - val_accuracy: 0.8197\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8678 - val_loss: 0.4109 - val_accuracy: 0.8361\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8719 - val_loss: 0.4104 - val_accuracy: 0.8525\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8719 - val_loss: 0.4130 - val_accuracy: 0.8525\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8760 - val_loss: 0.4161 - val_accuracy: 0.8525\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.2892 - accuracy: 0.8843 - val_loss: 0.4184 - val_accuracy: 0.8525\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2860 - accuracy: 0.8843 - val_loss: 0.4192 - val_accuracy: 0.8525\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8843 - val_loss: 0.4207 - val_accuracy: 0.8525\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8843 - val_loss: 0.4241 - val_accuracy: 0.8525\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2784 - accuracy: 0.8926 - val_loss: 0.4250 - val_accuracy: 0.8361\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8926 - val_loss: 0.4258 - val_accuracy: 0.8525\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2736 - accuracy: 0.8884 - val_loss: 0.4300 - val_accuracy: 0.8361\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8926 - val_loss: 0.4318 - val_accuracy: 0.8361\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2687 - accuracy: 0.8884 - val_loss: 0.4338 - val_accuracy: 0.8361\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2664 - accuracy: 0.8884 - val_loss: 0.4362 - val_accuracy: 0.8361\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.8926 - val_loss: 0.4381 - val_accuracy: 0.8361\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.8926 - val_loss: 0.4384 - val_accuracy: 0.8361\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8967 - val_loss: 0.4441 - val_accuracy: 0.8361\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.8967 - val_loss: 0.4471 - val_accuracy: 0.8361\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2554 - accuracy: 0.9008 - val_loss: 0.4496 - val_accuracy: 0.8361\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9050 - val_loss: 0.4520 - val_accuracy: 0.8361\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2511 - accuracy: 0.9050 - val_loss: 0.4514 - val_accuracy: 0.8361\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2497 - accuracy: 0.9050 - val_loss: 0.4536 - val_accuracy: 0.8361\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2470 - accuracy: 0.9050 - val_loss: 0.4515 - val_accuracy: 0.8361\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2450 - accuracy: 0.9050 - val_loss: 0.4524 - val_accuracy: 0.8361\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2431 - accuracy: 0.9050 - val_loss: 0.4554 - val_accuracy: 0.8361\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2409 - accuracy: 0.9050 - val_loss: 0.4582 - val_accuracy: 0.8361\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2390 - accuracy: 0.9132 - val_loss: 0.4598 - val_accuracy: 0.8361\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2375 - accuracy: 0.9091 - val_loss: 0.4598 - val_accuracy: 0.8361\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2357 - accuracy: 0.9091 - val_loss: 0.4632 - val_accuracy: 0.8361\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2338 - accuracy: 0.9132 - val_loss: 0.4660 - val_accuracy: 0.8361\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2318 - accuracy: 0.9132 - val_loss: 0.4679 - val_accuracy: 0.8361\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2302 - accuracy: 0.9132 - val_loss: 0.4688 - val_accuracy: 0.8361\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2284 - accuracy: 0.9174 - val_loss: 0.4700 - val_accuracy: 0.8361\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2268 - accuracy: 0.9215 - val_loss: 0.4703 - val_accuracy: 0.8361\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2250 - accuracy: 0.9215 - val_loss: 0.4722 - val_accuracy: 0.8361\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2235 - accuracy: 0.9215 - val_loss: 0.4752 - val_accuracy: 0.8361\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2217 - accuracy: 0.9215 - val_loss: 0.4783 - val_accuracy: 0.8361\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2200 - accuracy: 0.9215 - val_loss: 0.4798 - val_accuracy: 0.8361\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2185 - accuracy: 0.9215 - val_loss: 0.4808 - val_accuracy: 0.8361\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2170 - accuracy: 0.9298 - val_loss: 0.4829 - val_accuracy: 0.8361\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2156 - accuracy: 0.9298 - val_loss: 0.4848 - val_accuracy: 0.8361\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2140 - accuracy: 0.9298 - val_loss: 0.4851 - val_accuracy: 0.8361\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2122 - accuracy: 0.9298 - val_loss: 0.4878 - val_accuracy: 0.8361\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9298 - val_loss: 0.4907 - val_accuracy: 0.8361\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2089 - accuracy: 0.9298 - val_loss: 0.4939 - val_accuracy: 0.8361\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2075 - accuracy: 0.9339 - val_loss: 0.4959 - val_accuracy: 0.8361\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2061 - accuracy: 0.9339 - val_loss: 0.4952 - val_accuracy: 0.8361\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2041 - accuracy: 0.9339 - val_loss: 0.4971 - val_accuracy: 0.8361\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2027 - accuracy: 0.9339 - val_loss: 0.4995 - val_accuracy: 0.8361\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.2011 - accuracy: 0.9380 - val_loss: 0.5010 - val_accuracy: 0.8361\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1995 - accuracy: 0.9421 - val_loss: 0.5015 - val_accuracy: 0.8361\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1980 - accuracy: 0.9421 - val_loss: 0.5032 - val_accuracy: 0.8361\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1965 - accuracy: 0.9421 - val_loss: 0.5038 - val_accuracy: 0.8361\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1952 - accuracy: 0.9463 - val_loss: 0.5058 - val_accuracy: 0.8361\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1936 - accuracy: 0.9421 - val_loss: 0.5063 - val_accuracy: 0.8361\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1929 - accuracy: 0.9463 - val_loss: 0.5053 - val_accuracy: 0.8361\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1906 - accuracy: 0.9463 - val_loss: 0.5082 - val_accuracy: 0.8361\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.1893 - accuracy: 0.9504 - val_loss: 0.5137 - val_accuracy: 0.8361\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12f021f2-d0e0-460b-b1fd-abe422d03768",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8360655903816223\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6bba9a3b-7e90-47ce-a81b-fc33e3d7949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heart attack High risk probability: 0.9078938961029053\n"
     ]
    }
   ],
   "source": [
    "new_data = pd.DataFrame({\n",
    "    'age': [40],\n",
    "    'sex': [1],\n",
    "    'cp': [2],\n",
    "    'trtbps': [130],\n",
    "    'chol': [200],\n",
    "    'fbs': [0],\n",
    "    'restecg': [1],\n",
    "    'thalachh': [160],\n",
    "    'exng': [0],\n",
    "    'oldpeak': [1],\n",
    "    'slp': [2],\n",
    "    'caa': [0],\n",
    "    'thall': [3]\n",
    "})\n",
    "\n",
    "new_data_scaled = scaler.transform(new_data)\n",
    "prediction = model.predict(new_data_scaled)\n",
    "print(f'Heart attack High risk probability: {prediction[0][0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc7476-3ace-45a1-992b-fa9116bf7501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b2ec59-a0aa-4f0a-b88b-2d03c8386395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fe9d70-061e-4d2d-9cac-dbdae0a5f14e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Tensorflow-2.6.0",
   "language": "python",
   "name": "tensorflow-2.6.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
